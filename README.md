# AIGC-
AIGC 文本检测模型构建与算法优化
AI 大模型滥用现象导致 AIGC 检测成为关注焦点。本文聚焦于知识问答领域的检
测问题，基于选定的数据集，建立了合适的上下游网络完成 AIGC 检测，并将不同算法
进行比较，对 AIGC 检测提出见解。

数据预处理阶段，首先通过将 HC3 数据集中的问题输入三种主流中文 AI 大模型来
进行文本增强，随后对文本数据进行了删除不必要词、删除所有标点、串联问题和答案
和删除停用词等等处理。我们使用选择性文本增强(STA)的词角色划分方法计算两类文
本中所有词的加权对数似然比(wllr)和余弦相似度，从统计相关和语义相关两个角度来
筛选停用词，最终将文本中的 trivial 类和 venture 类词删除。依次对数据集采用了不同
的预处理方式，用于后续模型对不同预处理敏感度的对比。

网络搭建的上游任务中，我们采用了基于 word2vec 的固定编码和基于 transformer
上下文编码两种方式获得文本嵌入。前者需搭配如 DPCNN、TextCNN 等网络来进行文
本特征提取以得到文本嵌入，对于词向量的编码缺少上下文联系。而基于 transformer 的
预训练语言模型(PLM)如 BERT 由于其注意力机制能够考虑整个序列的信息，更好地考
虑语义关系。我们最终选定使用 PLM 进行文本嵌入，将固定编码形式作为我们的模型
对比。

我们构建了 FCNN 与 CNN 两种分类器来完成下游分类任务，同时引入批量归一化、
Dropout、L2 正则化措施控制过拟合风险。在完成超参数调优后，两种分类器在文本预
处理方法 1 上的测试集准确率分别达到 95.73%、95.63%。我们比较了不同文本预处理
方法与分类器组合检测效果，结果表明，分类器与预处理策略互动显著，简单去除特殊
符号效果最佳，去除标点或标志词可能对某些分类器产生负面影响。相比于 DPCNN 与
TextCNN，我们的检测器利用基于 Transfomer 的 PLM 能更好地捕获上下文信息，在本
检测任务上的表现均超过前两者。最后进行了消融实验，结果表明，我们的检测器各个
组件的设计是有效的。

为研究肉眼 AIGC 检测的可能性，在浏览数据集的基础上，我们从篇幅、词汇、词
性、标记词等方面为两类文本的特征寻找了一些统计依据。最终发现，AI 平均回答长度
比人类回答高 4.25%，但人类回答中使用词汇量是 AI 的 1.72 倍；AI 回答多使用名词、
动词、连词，体现出客观性和信息性，相反，人类回答中多用形容词，更具主观性；gold
类词具有高统计性和高语义性，人类回答中多使用语气词而 AI 回答中多使用一些表明
严谨性的词汇，这些可以作为二者区分的指示词。

最后，根据前文的研究对 AIGC 提出了一些我们的见解。

论文如下[aigc检测.pdf](https://github.com/user-attachments/files/18545543/aigc.pdf)
